{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Imports and Setup\n",
        "\n",
        "Let's start with the base imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn5_uV1HLvaz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "# Print Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogyryF2lFBL"
      },
      "source": [
        "## Utilities\n",
        "\n",
        "- Helper method to load an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y9R0Xllefec"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "    \n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bNk1gzh0TN"
      },
      "source": [
        "## Visualization tools\n",
        "\n",
        "To visualize the images with the proper detected boxes, keypoints and segmentation, we will use the TensorFlow Object Detection API. To install it we will clone the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi28cqGGFWnY"
      },
      "outputs": [],
      "source": [
        "# Clone the tensorflow models repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3pb_pXDjYA"
      },
      "source": [
        "Intalling the Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwdsBdGhFanc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash \n",
        "\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yDNgIx-kV7X"
      },
      "source": [
        "Now we can import the dependencies we will need later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JCeQU3fkayh"
      },
      "outputs": [],
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKtD0IeclbL5"
      },
      "source": [
        "### Load label map data (for plotting).\n",
        "\n",
        "Label maps correspond index numbers to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine.\n",
        "\n",
        "We are going, for simplicity, to load from the repository that we loaded the Object Detection API code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mucYUS6exUJ"
      },
      "outputs": [],
      "source": [
        "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muhUt-wWL582"
      },
      "source": [
        "## Loading the selected model from TensorFlow Hub\n",
        "\n",
        "Here we just need the model handle that was selected and use the Tensorflow Hub library to load it to memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBuD07fLlcEO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "print('loading model...')\n",
        "model_handle = \"https://tfhub.dev/tensorflow/efficientdet/d7/1\"\n",
        "hub_model = hub.load(model_handle)\n",
        "print('model loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTHsFjR6HNwb"
      },
      "source": [
        "[link text](https://)## Doing the inference\n",
        "\n",
        "To do the inference we just need to call our TF Hub loaded model.\n",
        "\n",
        "Things you can try:\n",
        "* Print out `result['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).\n",
        "* inspect other output keys present in the result. A full documentation can be seen on the models documentation page (pointing your browser to the model handle printed earlier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb_siXKcnnGC"
      },
      "outputs": [],
      "source": [
        "# running inference\n",
        "image_path = \"images/bottle_top.jpg\"\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "results = hub_model(image_np)\n",
        "\n",
        "# different object detection models have additional results\n",
        "# all of them are explained in the documentation\n",
        "result = {key:value.numpy() for key,value in results.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ5VYaBoeeFM"
      },
      "source": [
        "## Visualizing the results\n",
        "\n",
        "Here is where we will need the TensorFlow Object Detection API to show the squares from the inference step (and the keypoints when available).\n",
        "\n",
        "the full documentation of this method can be seen [here](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py)\n",
        "\n",
        "Here you can, for example, set `min_score_thresh` to other values (between 0 and 1) to allow more detections in or to filter out more detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O7rV8g9s8Bz"
      },
      "outputs": [],
      "source": [
        "label_id_offset = 0\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections[0],\n",
        "      result['detection_boxes'][0],\n",
        "      (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "      result['detection_scores'][0],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.25,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.imshow(image_np_with_detections[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect objects of all images in images directory"
      ],
      "metadata": {
        "id": "YJdMYwEggXUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import cv2\n",
        "\n",
        "image_names = os.listdir(\"images\")\n",
        "ncols = 3\n",
        "nrows = math.ceil(len(image_names) / ncols)\n",
        "figsize = [20, 20]\n",
        "\n",
        "print(f\"Cols: {ncols}; Rows: {nrows}\")\n",
        "\n",
        "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "\n",
        "\n",
        "for i, axi in enumerate(ax.flat):\n",
        "  try:\n",
        "    # Convert image to tensor\n",
        "    full_size_image = cv2.imread(os.path.join(\"images\", image_names[i]))\n",
        "    full_size_image = cv2.cvtColor(full_size_image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    image_np = cv2.resize(full_size_image, (224,224), interpolation=cv2.INTER_CUBIC)\n",
        "    image_np = tf.expand_dims(image_np, axis=0)\n",
        "    \n",
        "    # Detect objects in images\n",
        "    results = hub_model(image_np)\n",
        "    result = {key:value.numpy() for key,value in results.items()}\n",
        "\n",
        "    label_id_offset = 0\n",
        "    image_np_with_detections = np.array(image_np).copy()\n",
        "\n",
        "    # Draw bounding box \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections[0],\n",
        "        result['detection_boxes'][0],\n",
        "        (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "        result['detection_scores'][0],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.25,\n",
        "        agnostic_mode=False)\n",
        "    \n",
        "    axi.imshow(image_np_with_detections[0])\n",
        "  except:\n",
        "    print(f\"Failed at iteration {i} of {len(ax.flat)}\")\n",
        "    pass\n",
        "  \n",
        "\n",
        "plt.tight_layout(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GzpMRc5bgWR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect in Real-Time (only locally)"
      ],
      "metadata": {
        "id": "D9RhGlvwcX4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "1UqC2Bh0cW3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  (im_width, im_height) = frame.size\n",
        "  image_np = np.array(frame.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "  results = hub_model(image_np)\n",
        "  result = {key:value.numpy() for key,value in results.items()}\n",
        "\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                result['detection_boxes'],\n",
        "                result['detection_classes']+label_id_offset,\n",
        "                result['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.5,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "  cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Ssg7g3kLdMy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KcBghHRf8xd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NKtD0IeclbL5",
        "FTHsFjR6HNwb"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}