{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5692246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d82b5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import albumentations as A\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d00ed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6087965596632455008\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.config.list_physical_devices('gpu')\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "094000f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"DataCollection\"\n",
    "IMAGE_PATH = os.path.join(DATA_PATH, \"images\")\n",
    "LABEL_PATH = os.path.join(DATA_PATH, \"labels\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "VAL_PATH = os.path.join(DATA_PATH, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d80b9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = A.Compose([\n",
    "    A.Resize(height=224, width=224, always_apply=True),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "def resize_image(img_arr, bboxes, class_labels):\n",
    "    orig_img = img_arr.copy()\n",
    "    return resize_transform(image=orig_img, bboxes=bboxes, class_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "    x_min, y_min, x_max, y_max = [int(coord) for coord in bbox]\n",
    "   \n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, class_names):\n",
    "    img = image.copy()\n",
    "    for bbox, class_name in zip(bboxes, class_names):\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbdcd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(path):\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    label = root.find('object').find('name').text\n",
    "    width = int(root.find('size')[0].text)\n",
    "    height = int(root.find('size')[1].text)    \n",
    "\n",
    "    xmin = int(root.find('object').find('bndbox').find('xmin').text)\n",
    "    ymin = int(root.find('object').find('bndbox').find('ymin').text)\n",
    "    xmax = int(root.find('object').find('bndbox').find('xmax').text)\n",
    "    ymax = int(root.find('object').find('bndbox').find('ymax').text)\n",
    "    \n",
    "    coords = [xmin, ymin, xmax, ymax]\n",
    "    \n",
    "    return coords, label, width, height\n",
    "\n",
    "\n",
    "#get_annotation(f\"{os.path.join(LABEL_PATH, OBJECT_CLASS, file_name)}.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9653d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    byte_img = tf.io.read_file(path)\n",
    "    \n",
    "    return tf.io.decode_jpeg(byte_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "294e602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = load_image(os.path.join(TEST_PATH, '1957ca64-6caa-11ed-a345-eb2576af4ab5.png'))\n",
    "image_tensor = image_tensor[:,:,:3]\n",
    "image_tensor = image_tensor / 255\n",
    "image_tensor = tf.expand_dims(image_tensor, axis = 0)\n",
    "image_tensor = tf.cast(image_tensor, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8de22999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference___call___32344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_97451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_77595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_103456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_93843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_107064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_75975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d0/1\")\n",
    "detector_output = detector(image_tensor)\n",
    "class_ids = detector_output[\"detection_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "129addf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02784005, 0.99076486, 0.9836261 ], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_output['detection_boxes'].numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcdd4d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07271191, 0.06280702, 0.05780304, 0.05662147, 0.0563738 ,\n",
       "       0.05512178, 0.05494495, 0.05337929, 0.05296766, 0.05100016,\n",
       "       0.05059639, 0.04862596, 0.04518731, 0.04123715, 0.03656029,\n",
       "       0.03481734, 0.03369097, 0.03362564, 0.03267354, 0.03167859,\n",
       "       0.0312239 , 0.03082477, 0.03082346, 0.03038019, 0.02912157,\n",
       "       0.02880838, 0.02840948, 0.02828514, 0.02800387, 0.02759883,\n",
       "       0.02615781, 0.0258301 , 0.02570098, 0.02553835, 0.02547108,\n",
       "       0.02504924, 0.02461313, 0.02457962, 0.02446068, 0.0243536 ,\n",
       "       0.02404318, 0.02404007, 0.02396754, 0.02322334, 0.02319351,\n",
       "       0.02211283, 0.02201747, 0.02129038, 0.02090794, 0.02072514,\n",
       "       0.02070938, 0.02059726, 0.019908  , 0.01977079, 0.01935735,\n",
       "       0.01924396, 0.019167  , 0.01853512, 0.0184502 , 0.01813569,\n",
       "       0.01781076, 0.01756942, 0.01748498, 0.01725152, 0.01720189,\n",
       "       0.0171592 , 0.01695559, 0.01625103, 0.01610897, 0.01604885,\n",
       "       0.01598382, 0.01582605, 0.01578198, 0.01536114, 0.01531256,\n",
       "       0.01521521, 0.01513751, 0.01491956, 0.01485118, 0.01481162,\n",
       "       0.0147679 , 0.01472035, 0.01453677, 0.01443929, 0.01441414,\n",
       "       0.0142483 , 0.01420551, 0.01415132, 0.01410696, 0.01410695,\n",
       "       0.01409524, 0.01398827, 0.01397342, 0.01379948, 0.01373342,\n",
       "       0.013559  , 0.01316538, 0.01309858, 0.01309558, 0.01304727],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_output['detection_scores'][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7a8d00aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([0.07271191, 0.06280702, 0.05780304, 0.05662147, 0.0563738])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca168ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
